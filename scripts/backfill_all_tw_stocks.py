"""
å…¨å°è‚¡ä¸Šå¸‚æ«ƒæ­·å²æ•¸æ“šå›è£œè…³æœ¬
åŠŸèƒ½ï¼š
1. ä½¿ç”¨ twstock ç²å–æ‰€æœ‰ä¸Šå¸‚ (tse) èˆ‡ä¸Šæ«ƒ (otc) è‚¡ç¥¨ä»£ç¢¼
2. è‡ªå‹•åˆ¤æ–· yfinance å¾Œç¶´ (.TW / .TWO)
3. æŠ“å–å®Œæ•´æ­·å²æ•¸æ“š (Max History) ä¸¦å­˜å…¥ tw_stock_prices
"""
import sys
import os
from pathlib import Path
from loguru import logger
import time
import pandas as pd
import yfinance as yf
import twstock

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from data_loader import DatabaseConnector

def fetch_and_save_history(db, symbol):
    """æŠ“å–å®Œæ•´æ­·å²æ•¸æ“šä¸¦å­˜å…¥è³‡æ–™åº«"""
    try:
        # logger.info(f"ğŸ“¥ Fetching {symbol}...")
        ticker = yf.Ticker(symbol)
        df = ticker.history(period="max")
        
        if df.empty:
            # logger.warning(f"âš ï¸ {symbol} ç„¡æ•¸æ“š")
            return False
            
        df = df.reset_index()
        df.columns = df.columns.str.lower()
        if 'date' in df.columns:
            df = df.rename(columns={'date': 'trade_date'})
            
        # æº–å‚™æ•¸æ“š
        data_list = []
        for _, row in df.iterrows():
            data_list.append({
                'stock_code': symbol.replace('.TW', '').replace('.TWO', ''),
                'trade_date': row['trade_date'],
                'open_price': row['open'],
                'high_price': row['high'],
                'low_price': row['low'],
                'close_price': row['close'],
                'volume': int(row['volume'])
            })
            
        # æ‰¹é‡å¯«å…¥ (ä½¿ç”¨ UPSERT)
        query = """
            INSERT INTO tw_stock_prices 
            (stock_code, trade_date, open_price, high_price, low_price, close_price, volume)
            VALUES (%(stock_code)s, %(trade_date)s, %(open_price)s, %(high_price)s, %(low_price)s, %(close_price)s, %(volume)s)
            ON CONFLICT (stock_code, trade_date) 
            DO UPDATE SET
                close_price = EXCLUDED.close_price,
                volume = EXCLUDED.volume,
                updated_at = CURRENT_TIMESTAMP
        """
        
        # åˆ†æ‰¹åŸ·è¡Œä»¥é˜²å…§å­˜æº¢å‡º
        batch_size = 2000
        for i in range(0, len(data_list), batch_size):
            batch = data_list[i:i+batch_size]
            db.execute_batch(query, batch)
            
        return len(data_list)
        
    except Exception as e:
        logger.error(f"âŒ {symbol} è™•ç†å¤±æ•—: {e}")
        return 0

def backfill_all_tw_stocks():
    logger.info("ğŸš€ é–‹å§‹å…¨å°è‚¡ä¸Šå¸‚æ«ƒæ•¸æ“šå›è£œä»»å‹™...")
    db = DatabaseConnector()
    
    try:
        # 1. ç²å–ä¸¦åˆ†é¡è‚¡ç¥¨ä»£ç¢¼
        codes = twstock.codes
        tse_list = [] # ä¸Šå¸‚
        otc_list = [] # ä¸Šæ«ƒ
        
        for code, info in codes.items():
            if info.type == 'è‚¡ç¥¨':
                if info.market == 'ä¸Šå¸‚':
                    tse_list.append(code)
                elif info.market == 'ä¸Šæ«ƒ':
                    otc_list.append(code)
                    
        logger.info(f"ğŸ“‹ ç™¼ç¾ä¸Šå¸‚è‚¡ç¥¨: {len(tse_list)} æª”")
        logger.info(f"ğŸ“‹ ç™¼ç¾ä¸Šæ«ƒè‚¡ç¥¨: {len(otc_list)} æª”")
        logger.info(f"ğŸ“Š ç¸½è¨ˆ: {len(tse_list) + len(otc_list)} æª”")
        
        # 2. åŸ·è¡Œå›è£œ (å…ˆä¸Šå¸‚å¾Œä¸Šæ«ƒ)
        total_processed = 0
        total_records = 0
        
        all_targets = []
        for c in tse_list:
            all_targets.append({'code': c, 'symbol': f"{c}.TW"})
        for c in otc_list:
            all_targets.append({'code': c, 'symbol': f"{c}.TWO"})
            
        start_time = time.time()
        
        for i, target in enumerate(all_targets):
            symbol = target['symbol']
            
            # æ¯ 50 æª”é¡¯ç¤ºä¸€æ¬¡é€²åº¦
            if i % 50 == 0:
                elapsed = time.time() - start_time
                avg_time = elapsed / (i + 1)
                remaining = (len(all_targets) - i) * avg_time
                logger.info(f"ğŸ”„ é€²åº¦: {i}/{len(all_targets)} ({i/len(all_targets)*100:.1f}%) | é è¨ˆå‰©é¤˜æ™‚é–“: {remaining/60:.1f} åˆ†")
            
            count = fetch_and_save_history(db, symbol)
            if count:
                # logger.success(f"âœ… {symbol} æ›´æ–° {count} ç­†")
                total_records += count
                total_processed += 1
            else:
                # logger.warning(f"âš ï¸ {symbol} ç„¡æ•¸æ“šæˆ–æ›´æ–°å¤±æ•—")
                pass
                
            # è¼•å¾®é™é€Ÿé¿å…è¢«å° IP
            # time.sleep(0.2) 

        logger.success(f"ğŸ å…¨å°è‚¡å›è£œå®Œæˆï¼å…±è™•ç† {total_processed} æª”è‚¡ç¥¨ï¼Œå¯«å…¥ {total_records} ç­†æ•¸æ“šã€‚")

    except Exception as e:
        logger.error(f"è…³æœ¬åŸ·è¡ŒéŒ¯èª¤: {e}")
    finally:
        db.close()

if __name__ == '__main__':
    backfill_all_tw_stocks()
