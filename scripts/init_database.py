"""
è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬
åŸ·è¡Œæ­¤è…³æœ¬å°‡ï¼š
1. æ¸¬è©¦è³‡æ–™åº«é€£ç·š
2. åŸ·è¡Œ schema.sql å»ºç«‹æ‰€æœ‰è¡¨æ ¼
3. é©—è­‰è¡¨æ ¼å»ºç«‹æˆåŠŸ
4. æ’å…¥åˆå§‹é…ç½®è³‡æ–™
"""

import sys
import os
from pathlib import Path
import psycopg2
from psycopg2 import sql
from loguru import logger

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from config.settings import DATABASE_CONFIG

# é…ç½®æ—¥èªŒ
logger.remove()
logger.add(sys.stdout, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")
logger.add("logs/init_database.log", rotation="10 MB")


def test_connection():
    """æ¸¬è©¦è³‡æ–™åº«é€£ç·š"""
    logger.info("ğŸ” æ¸¬è©¦è³‡æ–™åº«é€£ç·š...")
    
    try:
        conn = psycopg2.connect(**DATABASE_CONFIG)
        cursor = conn.cursor()
        cursor.execute("SELECT version();")
        version = cursor.fetchone()
        logger.success(f"âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸï¼")
        logger.info(f"   PostgreSQL ç‰ˆæœ¬: {version[0]}")
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        return False


def execute_schema():
    """åŸ·è¡Œ schema.sql å»ºç«‹æ‰€æœ‰è¡¨æ ¼"""
    logger.info("ğŸ“ åŸ·è¡Œ schema.sql...")
    
    schema_file = Path(__file__).parent.parent / 'database' / 'schema.sql'
    
    if not schema_file.exists():
        logger.error(f"âŒ æ‰¾ä¸åˆ° schema.sql æª”æ¡ˆ: {schema_file}")
        return False
    
    try:
        # è®€å– SQL æª”æ¡ˆ
        with open(schema_file, 'r', encoding='utf-8') as f:
            schema_sql = f.read()
        
        # åŸ·è¡Œ SQL
        conn = psycopg2.connect(**DATABASE_CONFIG)
        cursor = conn.cursor()
        
        logger.info("   åŸ·è¡Œ SQL æŒ‡ä»¤...")
        cursor.execute(schema_sql)
        conn.commit()
        
        logger.success("âœ… Schema åŸ·è¡ŒæˆåŠŸï¼")
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ Schema åŸ·è¡Œå¤±æ•—: {e}")
        return False


def verify_tables():
    """é©—è­‰è¡¨æ ¼å»ºç«‹æˆåŠŸ"""
    logger.info("ğŸ” é©—è­‰è¡¨æ ¼å»ºç«‹ç‹€æ…‹...")
    
    expected_tables = [
        # åŸå§‹è³‡æ–™å±¤
        'tw_stock_info', 'tw_stock_prices',
        'us_stock_info', 'us_stock_prices',
        'gold_prices', 'exchange_rates',
        'macro_indicators', 'financial_news',
        # é è¨ˆç®—å±¤
        'technical_indicators', 'quant_scores',
        # AI å¿«å–å±¤
        'ai_reports', 'similarity_matrix',
        # é€²éšåˆ†æå±¤
        'shareholder_dispersion', 'institutional_holdings_13f',
        'portfolio_performance', 'backtest_results',
        'behavioral_metrics', 'stress_test_results',
        # ç³»çµ±ç®¡ç†å±¤
        'sync_status', 'system_config'
    ]
    
    try:
        conn = psycopg2.connect(**DATABASE_CONFIG)
        cursor = conn.cursor()
        
        # æŸ¥è©¢æ‰€æœ‰è¡¨æ ¼
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
            ORDER BY table_name;
        """)
        
        actual_tables = [row[0] for row in cursor.fetchall()]
        
        # æª¢æŸ¥æ¯å€‹é æœŸçš„è¡¨æ ¼
        missing_tables = []
        found_tables = []
        
        for table in expected_tables:
            if table in actual_tables:
                found_tables.append(table)
            else:
                missing_tables.append(table)
        
        # è¼¸å‡ºçµæœ
        logger.info(f"   é æœŸè¡¨æ ¼æ•¸ï¼š{len(expected_tables)}")
        logger.info(f"   å¯¦éš›å»ºç«‹æ•¸ï¼š{len(found_tables)}")
        
        if missing_tables:
            logger.warning(f"âš ï¸  ç¼ºå°‘è¡¨æ ¼ ({len(missing_tables)}):")
            for table in missing_tables:
                logger.warning(f"      - {table}")
        
        if found_tables:
            logger.success(f"âœ… æˆåŠŸå»ºç«‹ {len(found_tables)} å€‹è¡¨æ ¼ï¼š")
            
            # åˆ†é¡é¡¯ç¤º
            categories = {
                'åŸå§‹è³‡æ–™å±¤': ['tw_stock_info', 'tw_stock_prices', 'us_stock_info', 'us_stock_prices', 
                              'gold_prices', 'exchange_rates', 'macro_indicators', 'financial_news'],
                'é è¨ˆç®—å±¤': ['technical_indicators', 'quant_scores'],
                'AI å¿«å–å±¤': ['ai_reports', 'similarity_matrix'],
                'é€²éšåˆ†æå±¤': ['shareholder_dispersion', 'institutional_holdings_13f', 
                              'portfolio_performance', 'backtest_results', 
                              'behavioral_metrics', 'stress_test_results'],
                'ç³»çµ±ç®¡ç†å±¤': ['sync_status', 'system_config']
            }
            
            for category, tables in categories.items():
                category_tables = [t for t in tables if t in found_tables]
                if category_tables:
                    logger.info(f"   ğŸ“Š {category}: {len(category_tables)} å€‹")
        
        # æŸ¥è©¢è¦–åœ–
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.views 
            WHERE table_schema = 'public'
            ORDER BY table_name;
        """)
        
        views = [row[0] for row in cursor.fetchall()]
        if views:
            logger.info(f"   ğŸ‘ï¸  è¦–åœ–: {len(views)} å€‹ ({', '.join(views)})")
        
        cursor.close()
        conn.close()
        
        return len(missing_tables) == 0
        
    except Exception as e:
        logger.error(f"âŒ é©—è­‰è¡¨æ ¼å¤±æ•—: {e}")
        return False


def check_indexes():
    """æª¢æŸ¥ç´¢å¼•å»ºç«‹ç‹€æ³"""
    logger.info("ğŸ” æª¢æŸ¥ç´¢å¼•å»ºç«‹ç‹€æ³...")
    
    try:
        conn = psycopg2.connect(**DATABASE_CONFIG)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                schemaname,
                tablename,
                indexname
            FROM pg_indexes
            WHERE schemaname = 'public'
            ORDER BY tablename, indexname;
        """)
        
        indexes = cursor.fetchall()
        logger.success(f"âœ… æˆåŠŸå»ºç«‹ {len(indexes)} å€‹ç´¢å¼•")
        
        # çµ±è¨ˆæ¯å€‹è¡¨æ ¼çš„ç´¢å¼•æ•¸é‡
        from collections import defaultdict
        table_indexes = defaultdict(int)
        for _, table, _ in indexes:
            table_indexes[table] += 1
        
        logger.info("   ä¸»è¦è¡¨æ ¼ç´¢å¼•çµ±è¨ˆï¼š")
        for table in ['tw_stock_prices', 'us_stock_prices', 'technical_indicators', 'quant_scores']:
            count = table_indexes.get(table, 0)
            logger.info(f"      {table}: {count} å€‹ç´¢å¼•")
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ æª¢æŸ¥ç´¢å¼•å¤±æ•—: {e}")
        return False


def insert_sample_config():
    """æ’å…¥ç¯„ä¾‹é…ç½®è³‡æ–™"""
    logger.info("ğŸ“ æ’å…¥ç¯„ä¾‹é…ç½®è³‡æ–™...")
    
    try:
        conn = psycopg2.connect(**DATABASE_CONFIG)
        cursor = conn.cursor()
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰è³‡æ–™
        cursor.execute("SELECT COUNT(*) FROM system_config;")
        count = cursor.fetchone()[0]
        
        if count > 0:
            logger.info(f"   å·²æœ‰ {count} ç­†é…ç½®è³‡æ–™ï¼Œè·³éæ’å…¥")
        else:
            logger.info("   æ’å…¥é è¨­é…ç½®...")
            # é…ç½®å·²åœ¨ schema.sql ä¸­å®šç¾©ï¼Œæ­¤è™•ä¸éœ€é¡å¤–æ’å…¥
        
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ’å…¥é…ç½®å¤±æ•—: {e}")
        return False


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 60)
    logger.info("ğŸš€ é–‹å§‹åˆå§‹åŒ–å°ˆæ¥­é‡‘èè³‡æ–™åº«")
    logger.info("=" * 60)
    
    # æ­¥é©Ÿ 1: æ¸¬è©¦é€£ç·š
    if not test_connection():
        logger.error("âŒ åˆå§‹åŒ–å¤±æ•—ï¼šç„¡æ³•é€£ç·šè³‡æ–™åº«")
        logger.info("   è«‹æª¢æŸ¥ï¼š")
        logger.info("   1. Docker å®¹å™¨æ˜¯å¦æ­£åœ¨é‹è¡Œï¼Ÿ")
        logger.info("   2. .env æª”æ¡ˆä¸­çš„è³‡æ–™åº«è¨­å®šæ˜¯å¦æ­£ç¢ºï¼Ÿ")
        logger.info("   3. è³‡æ–™åº«å¯†ç¢¼æ˜¯å¦æ­£ç¢ºï¼Ÿ")
        return False
    
    # æ­¥é©Ÿ 2: åŸ·è¡Œ Schema
    if not execute_schema():
        logger.error("âŒ åˆå§‹åŒ–å¤±æ•—ï¼šç„¡æ³•åŸ·è¡Œ schema.sql")
        return False
    
    # æ­¥é©Ÿ 3: é©—è­‰è¡¨æ ¼
    if not verify_tables():
        logger.warning("âš ï¸  éƒ¨åˆ†è¡¨æ ¼å»ºç«‹å¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡Œ...")
    
    # æ­¥é©Ÿ 4: æª¢æŸ¥ç´¢å¼•
    check_indexes()
    
    # æ­¥é©Ÿ 5: æ’å…¥é…ç½®
    insert_sample_config()
    
    logger.info("=" * 60)
    logger.success("ğŸ‰ è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆï¼")
    logger.info("=" * 60)
    logger.info("ğŸ“Š ä¸‹ä¸€æ­¥ï¼š")
    logger.info("   1. å®‰è£ Python ä¾è³´ï¼špip install -r requirements.txt")
    logger.info("   2. é…ç½® API é‡‘é‘°ï¼šè¤‡è£½ config/.env.example ç‚º .env ä¸¦å¡«å…¥é‡‘é‘°")
    logger.info("   3. é–‹å§‹è³‡æ–™å›æº¯ï¼špython scripts/run_backfill.py --phase 1")
    logger.info("=" * 60)
    
    return True


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
