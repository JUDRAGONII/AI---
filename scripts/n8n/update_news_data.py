"""
N8N è‡ªå‹•åŒ–è…³æœ¬ - é‡‘èæ–°èçˆ¬èŸ²èˆ‡æ‘˜è¦
ç”¨æ–¼æ¯æ—¥å®šæœŸåŸ·è¡Œ (ä¾‹å¦‚æ¯ 4 å°æ™‚)ï¼Œæ›´æ–°æœ€æ–°å¸‚å ´æ–°è
"""
import sys
import os
from pathlib import Path
from datetime import datetime
import pandas as pd
from loguru import logger
import time

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from api_clients.news_client import NewsClient
from data_loader import DatabaseConnector

def update_news_data():
    """æ›´æ–°é‡‘èæ–°èæ•¸æ“š"""
    
    logger.info("=" * 60)
    logger.info("ğŸš€ [N8N] é–‹å§‹åŸ·è¡Œé‡‘èæ–°èæ›´æ–°")
    logger.info("=" * 60)
    
    db = DatabaseConnector()
    client = NewsClient()
    
    try:
        # 0. ç¢ºä¿æ–°èè¡¨å­˜åœ¨
        db.execute_query("""
            CREATE TABLE IF NOT EXISTS financial_news (
                id SERIAL PRIMARY KEY,
                news_id VARCHAR(255) UNIQUE,
                title TEXT,
                content TEXT,
                source VARCHAR(100),
                url TEXT,
                published_at TIMESTAMP,
                sentiment_score FLOAT,
                related_symbols TEXT[],
                categories TEXT[],
                market VARCHAR(10) DEFAULT 'GLOBAL',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            CREATE INDEX IF NOT EXISTS idx_news_published_at ON financial_news(published_at DESC);
            CREATE INDEX IF NOT EXISTS idx_news_related_symbols ON financial_news USING GIN (related_symbols);
        """)
        
        # 1. ç²å–å¸‚å ´ç„¦é»æ–°è
        logger.info("ğŸ“° ç²å–å¸‚å ´ç„¦é»æ–°è...")
        market_news = client.get_market_news(limit=20)
        
        # 2. ç²å–é‡é»æŒè‚¡æ–°è
        logger.info("ğŸ” ç²å–é‡é»æŒè‚¡æ–°è...")
        # é€™è£¡åªæŠ“æœ€é‡è¦çš„å¹¾æª”ï¼Œé¿å… API é¡åº¦è€—ç›¡ (Alpha Vantage é™åˆ¶)
        key_stocks = ['AAPL', 'NVDA', 'TSLA', '2330', '2454'] 
        stock_news = []
        
        # ç‚ºäº†ç¯€çœé¡åº¦ï¼Œé€™è£¡éš¨æ©Ÿé¸ 2 æª”æˆ–è¼ªè©¢ (ç°¡å–®èµ·è¦‹ï¼Œé€™æ¬¡åªæŠ“å‰ 2 æª” + TSMC)
        target_stocks = ['2330', 'AAPL']
        
        for symbol in target_stocks:
            try:
                news = client.get_stock_news(symbol, limit=5)
                stock_news.extend(news)
                time.sleep(12) # Alpha Vantage 5 req/min => 12s interval
            except Exception as e:
                logger.error(f"ç²å– {symbol} æ–°èå¤±æ•—: {e}")
        
        # åˆä½µæ–°è (å»é‡åœ¨ DB å±¤è™•ç†)
        all_news = market_news + stock_news
        
        logger.info(f"ğŸ“‹ å…±ç²å– {len(all_news)} å‰‡æ–°èï¼Œæº–å‚™å¯«å…¥è³‡æ–™åº«...")
        
        # 3. å¯«å…¥è³‡æ–™åº«
        inserted_count = 0
        skipped_count = 0
        
        for item in all_news:
            try:
                # è™•ç† list è½‰ array string
                # related_symbols æ˜¯ list
                
                query = """
                    INSERT INTO financial_news 
                    (news_id, title, content, source, url, published_at, sentiment_score, related_symbols, categories, market)
                    VALUES (%(news_id)s, %(title)s, %(content)s, %(source)s, %(url)s, %(published_at)s, %(sentiment_score)s, %(related_symbols)s, %(categories)s, %(market)s)
                    ON CONFLICT (news_id) DO NOTHING
                """
                
                # ç°¡å–®åˆ¤æ–·å¸‚å ´
                market = 'GLOBAL'
                symbols = item.get('related_symbols', [])
                if any('.TW' in s or s in ['2330', '2454'] for s in symbols):
                    market = 'TW'
                elif any(s in ['AAPL', 'NVDA', 'SPY'] for s in symbols):
                    market = 'US'
                
                params = {
                    'news_id': item['news_id'],
                    'title': item['title'],
                    'content': item['content'],
                    'source': item['source'],
                    'url': item['url'],
                    'published_at': item['published_at'],
                    'sentiment_score': item['sentiment_score'],
                    'related_symbols': list(set(item['related_symbols'])), # å»é‡
                    'categories': item.get('categories', []),
                    'market': market
                }
                
                # Execute singly to separate errors? Or batch?
                # Using execute_batch would be faster but single is safer for error counting
                # Given volume is small (<50), single is fine.
                
                # But DatabaseConnector usually expose execute_query.
                # psycopg2 params adaptation handles list -> array.
                
                db.execute_query(query, params)
                inserted_count += 1
                
            except Exception as e:
                # å¯èƒ½æ˜¯é‡è¤‡éµæˆ–å…¶ä»–éŒ¯èª¤ (ä½†ç”¨äº† ON CONFLICT DO NOTHING)
                # logger.warning(f"å¯«å…¥æ–°èå¤±æ•—: {e}")
                skipped_count += 1
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š æ–°èæ›´æ–°çµ±è¨ˆ")
        logger.info(f"   ç²å–ç¸½æ•¸: {len(all_news)}")
        logger.info(f"   æˆåŠŸè™•ç†: {inserted_count}") # æ³¨æ„ï¼šé€™è£¡å…¶å¯¦ä¸ç®—çœŸæ­£çš„ 'inserted' æ•¸é‡ï¼Œå› ç‚º execute_query ä¸å›å‚³å—å½±éŸ¿è¡Œæ•¸
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ è…³æœ¬åŸ·è¡Œå¤±æ•—: {e}")
        sys.exit(1)
    finally:
        db.close()

if __name__ == '__main__':
    update_news_data()
